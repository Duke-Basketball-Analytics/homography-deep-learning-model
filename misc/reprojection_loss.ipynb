{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to sys.path: /Users/matth/OneDrive/Documents/DukeMIDS/DataPlus/Basketball/DL_homography/homography_deep_learning_model\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root absolute path\n",
    "project_root = os.path.abspath(\"..\")  # Move up one level to project root\n",
    "\n",
    "# Add project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to sys.path:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model.reprojection_loss import ReprojectionLoss\n",
    "from dataset.point_selection import sample_evenly_spaced_points\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matth/OneDrive/Documents/DukeMIDS/DataPlus/Basketball/DL_homography/DL_homography_matrices/OFFENSE-1\n"
     ]
    }
   ],
   "source": [
    "gparent_directory = os.path.abspath(\"../..\")\n",
    "homography_directory = os.path.join(gparent_directory, \"DL_homography_matrices\", \"OFFENSE-1\")\n",
    "mask_directory = os.path.join(gparent_directory, \"DL_masks\", \"OFFENSE-1\")\n",
    "print(homography_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[180., 194.,   1.],\n",
      "         [ 87., 163.,   1.],\n",
      "         [201.,  80.,   1.],\n",
      "         [104.,  23.,   1.],\n",
      "         [195.,  81.,   1.],\n",
      "         [170.,  71.,   1.],\n",
      "         [173., 160.,   1.],\n",
      "         [177., 126.,   1.],\n",
      "         [102., 165.,   1.],\n",
      "         [148.,  98.,   1.]]])\n",
      "torch.Size([1, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "# One test homography matrix \n",
    "files = sorted(os.listdir(homography_directory))\n",
    "file = \"Frame_0.npy\"\n",
    "\n",
    "# Load H_gt [1,3,3] and image mask [224,224]\n",
    "mask = np.load(os.path.join(mask_directory, file))\n",
    "H_gt = np.array([np.load(os.path.join(homography_directory, file))])\n",
    "H_gt = torch.tensor(H_gt, dtype=torch.float32)\n",
    "\n",
    "# Generate valid points for the mask\n",
    "points = np.array([sample_evenly_spaced_points(mask=mask, num_points=10, seed = 42)])\n",
    "points = torch.tensor(points, dtype=torch.float32) \n",
    "print(points)\n",
    "print(points.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprojection_loss = ReprojectionLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(H_gt.shape)\n",
    "H_gt.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "error = reprojection_loss.generate_reprojection(H_pred=H_gt, H_gt=H_gt, points=points)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perturbed_matrix(H, total_mse):\n",
    "    errors = torch.randn(9, dtype=H.dtype, device=H.device)  # Random errors for 9 elements\n",
    "    errors *= torch.sqrt(torch.tensor(total_mse) / torch.sum(errors**2))  # Normalize to total MSE\n",
    "    \n",
    "    perturbed_H = H.clone()\n",
    "    perturbed_H += errors.reshape(3, 3)  # Apply errors to the whole matrix\n",
    "    \n",
    "    # Optionally re-normalize h33 to 1\n",
    "    # perturbed_H /= perturbed_H[2, 2]\n",
    "    return perturbed_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.5514e-05, -1.7402e-05,  9.9974e-01],\n",
       "         [ 7.0484e-06,  2.0510e-04, -2.2602e-02],\n",
       "         [-5.0311e-08,  2.4724e-09,  4.3624e-04]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_gt[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = np.random.randn(9)  # Random errors for 8 elements\n",
    "errors *= np.sqrt(0.05 / np.sum(errors**2))\n",
    "errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08040371,  0.14968848, -0.01912936],\n",
       "       [-0.08489319,  0.07019564,  0.07660192]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.reshape(2, 4)[:2, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  tensor(1.1111e-05)\n",
      "[tensor(40928400.)]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through different MSE values\n",
    "mse_values = np.linspace(0.0001, 10, 1)\n",
    "reprojection_errors = []\n",
    "\n",
    "for mse in mse_values:\n",
    "    H_perturbed = generate_perturbed_matrix(H_gt, mse)\n",
    "    error = reprojection_loss.generate_reprojection(H_pred=H_perturbed, H_gt=H_gt, points=points)\n",
    "    reprojection_errors.append(torch.mean(error))\n",
    "    print(\"MSE: \", torch.nn.functional.mse_loss(H_perturbed, H_gt))\n",
    "\n",
    "print(reprojection_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000e-07, 1.11112e-02, 2.22223e-02, 3.33334e-02, 4.44445e-02,\n",
       "       5.55556e-02, 6.66667e-02, 7.77778e-02, 8.88889e-02, 1.00000e-01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.0000001, 0.1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-05])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homography_DLmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
